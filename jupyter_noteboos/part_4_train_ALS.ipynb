{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1a8959",
   "metadata": {},
   "source": [
    "#### Подключаемся к серверy\n",
    "\n",
    "```bash\n",
    "ssh 305_koryagin@37.139.32.56 -i ./id_rsa_305_koryagin.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae2e57",
   "metadata": {},
   "source": [
    "#### Запускаем spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842fb081",
   "metadata": {},
   "source": [
    "```python\n",
    "/spark2.4/bin/pyspark\n",
    "\n",
    "from pyspark.shell import sc\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707710ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_week(df, week_col_name, test_size_weeks):\n",
    "    \"\"\"\n",
    "    Разделение на train и test по неделям\n",
    "    :param df: исходный датафрейм\n",
    "    :param week_col_name: название колонки с номерами недели в году\n",
    "    :param test_size_weeks: число недель для теста\n",
    "    :return: 2 датасета\n",
    "    \"\"\"\n",
    "    threshold_week = int(data.select(F.max(week_col_name)).collect()[0][0]) - test_size_weeks\n",
    "    train = df.filter(F.col(week_col_name) < threshold_week)\n",
    "    test = df.filter(F.col(week_col_name) >= threshold_week)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6df696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_for_als(df, user_col_name, item_col_name, rating_col_name):\n",
    "    \"\"\"\n",
    "    Преобразование для ALS\n",
    "    :param df: исходный датафрейм \n",
    "    :param user_col_name: имя колонки пользователей/покупателей\n",
    "    :param item_col_name: имя колонки с товарами\n",
    "    :param rating_col_name: имя колонки с рейтингом (сумма, количество продаж)\n",
    "    :return: преобразованный датафрейм\n",
    "    \"\"\"\n",
    "    return df \\\n",
    "        .select(user_col_name, item_col_name, rating_col_name) \\\n",
    "        .groupBy(user_col_name, item_col_name).sum(rating_col_name) \\\n",
    "        .withColumnRenamed(existing='sum(quantity)', new='quantity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccdf981",
   "metadata": {},
   "source": [
    "## Создание DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311f4e2",
   "metadata": {},
   "source": [
    "```python\n",
    "# для начала готовим DataFrame\n",
    "data = spark.read.parquet(\"input_csv_for_recommend_system/data.parquet\")\n",
    "data.show(n=5, truncate=True)\n",
    "```\n",
    "\n",
    "<details>\n",
    "    <summary> → вывод консоли SPARK</summary>\n",
    "    \n",
    "![Title](../images/2021-04-25_125511.jpg)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24774b7",
   "metadata": {},
   "source": [
    "```python\n",
    "# Введем колонку с номером недели\n",
    "data = data.withColumn(colName='week_of_year', col=F.weekofyear(F.col('sale_date_date')))  \n",
    "\n",
    "# Разделим набор данных на тренировочную и тестовую выборки\n",
    "data_train, data_test = train_test_split_by_week(df=data, week_col_name='week_of_year', test_size_weeks=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b6edac",
   "metadata": {},
   "source": [
    "## Преобразование данных для ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f34a19",
   "metadata": {},
   "source": [
    "```python\n",
    "# Преобразуем данные для ALS\n",
    "train = transform_for_als(data_train, 'contact_id', 'product_id', 'quantity')\n",
    "test = transform_for_als(data_test, 'contact_id', 'product_id', 'quantity')\n",
    "\n",
    "test.show(n=5, truncate=True)\n",
    "```\n",
    "\n",
    "<details>\n",
    "    <summary> → вывод консоли SPARK</summary>\n",
    "\n",
    "```bash\n",
    "+----------+----------+-------------------+\n",
    "|contact_id|product_id|           quantity|\n",
    "+----------+----------+-------------------+\n",
    "|   2737106|     83462|                3.0|\n",
    "|   1387649|    124839|               20.0|\n",
    "|    171180|     76190| 0.4000000059604645|\n",
    "|    107728|    147802|0.30000000447034836|\n",
    "|    993804|    158586|               30.0|\n",
    "+----------+----------+-------------------+\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57221e08",
   "metadata": {},
   "source": [
    "## Обучение модели и ее сохранение ее в файл"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b0044",
   "metadata": {},
   "source": [
    "```python\n",
    "# Обучениеё\n",
    "model = ALS.trainImplicit(ratings=train, rank=10, alpha=0.01, nonnegative=True, seed=42)\n",
    "\n",
    "# Save model\n",
    "model.save(sc, \"ml_models/myCollaborativeFilter\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf43810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
